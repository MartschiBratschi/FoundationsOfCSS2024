{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Correlation of Future Orientation Index and Gross Domestic Product\n",
    "## Tasks\n",
    "\n",
    "In this exercise, we try to reproduce the findings of the article “Quantifying the Advantage of Looking Forward” http://www.nature.com/articles/srep00350.\n",
    "\n",
    "According to the study, the GDP per capita of countries is positively correlated to how much their population searches in Google for the next year, relative to how much they search for the previous year.\n",
    "\n",
    "This ratio is called the Future Orientation Index (FOI). So for example for the year 2017 the FOI can be calculated as: FOI = number of searches for the term “2018” / number of searches for the term “2016”.\n",
    "\n",
    "You will do the following tasks:\n",
    "1. Aquire World Bank Data\n",
    "2. Calculate the Future Orientation Index in Google Trends\n",
    "3. Test the correlation between GDP and FOI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install requirements. \n",
    "\n",
    "The following cell contains all the necessary dependencies needed for this task. If you run the cell everything will be installed.  \n",
    "* [`wbgapi`](https://github.com/tgherzog/wbgapi) is a Python package which provides modern, pythonic access to the World Bank's data API. [Here](https://github.com/tgherzog/wbgapi) is the documentation of `wbgapi`.\n",
    "* [`pandas`](https://pandas.pydata.org/docs/index.html) is a Python package for creating and working with tabular data. [Here](https://pandas.pydata.org/docs/reference/index.html) is the documentation of `pandas`.\n",
    "* [`matplotlib`](https://matplotlib.org/) is a Python package for creating plots. [Here](https://matplotlib.org/stable/api/index.html) is the documentation of `matplotlib`.\n",
    "* [`scipy`](https://scipy.org/) is a Python package with different algorithms for scientific computing. [Here](https://docs.scipy.org/doc/scipy/reference/index.html#scipy-api) is the documentation of `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install wbgapi\n",
    "! pip install pandas\n",
    "! pip install matplotlib\n",
    "! pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import requirements\n",
    "The cell below imports all necessary dependancies. Make sure they are installed (see cell above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wbgapi as wb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 World Bank Data\n",
    "## 1.1 Download WDI data\n",
    "\n",
    "From the WDI we need three indicators:\n",
    "* Gross Domestic Product (GDP) per capita corrected by the Purchase Power Parity (PPP in current or 2005 international $, `\"NY.GDP.PCAP.PP.KD\"`)\n",
    "* The amount of Internet users (per 100 people, `\"IT.NET.USER.ZS\"`\n",
    "* The total population (described as as \"Population, Total\", `\"SP.POP.TOTL\"`)\n",
    "\n",
    "In the following code chunk, download all data (including extras) for all countries in year 2014 and save it as a pandas data frame. See [here](https://github.com/tgherzog/wbgapi#accessing-data) how to use the `data` subpackage of `wbgapi`.\n",
    "\n",
    "Hint: To remove aggregates (economic regions defined by the World Bank) and include only countries, use `skipAggs=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    economy                Country  IT.NET.USER.ZS  NY.GDP.PCAP.PP.KD  \\\n",
      "0       ZWE               Zimbabwe         16.3647        3588.862715   \n",
      "1       ZMB                 Zambia          6.5000        3621.466084   \n",
      "2       YEM            Yemen, Rep.         22.5500                NaN   \n",
      "3       PSE     West Bank and Gaza         53.6652        5990.426615   \n",
      "4       VIR  Virgin Islands (U.S.)         50.0700       42698.552089   \n",
      "..      ...                    ...             ...                ...   \n",
      "212     AND                Andorra         86.1000       61700.237094   \n",
      "213     ASM         American Samoa             NaN                NaN   \n",
      "214     DZA                Algeria         29.5000       15249.570446   \n",
      "215     ALB                Albania         54.3000       12909.240795   \n",
      "216     AFG            Afghanistan          7.0000        3024.982120   \n",
      "\n",
      "     SP.POP.TOTL  \n",
      "0     13855753.0  \n",
      "1     15737793.0  \n",
      "2     27753304.0  \n",
      "3      4173398.0  \n",
      "4       107882.0  \n",
      "..           ...  \n",
      "212      71621.0  \n",
      "213      52217.0  \n",
      "214   38760168.0  \n",
      "215    2889104.0  \n",
      "216   32716210.0  \n",
      "\n",
      "[217 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import wbgapi as wb\n",
    "\n",
    "# List of indicators\n",
    "indicators = ['NY.GDP.PCAP.PP.KD', 'IT.NET.USER.ZS', 'SP.POP.TOTL']\n",
    "\n",
    "try:\n",
    "    # Fetch data for all countries in 2014\n",
    "    data = wb.data.DataFrame(indicators, time=2014,\n",
    "                             skipAggs=True, columns='series', labels=True)\n",
    "\n",
    "    # Reset index for easier readability\n",
    "    data.reset_index(inplace=True)\n",
    "\n",
    "    print(data)\n",
    "except wb.APIError as e:\n",
    "    print(f\"API error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now drop any row that has `NaN` for this you can use `pandas` [`dropna`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    economy                Country  Internet users  \\\n",
      "0       ZWE               Zimbabwe         16.3647   \n",
      "1       ZMB                 Zambia          6.5000   \n",
      "3       PSE     West Bank and Gaza         53.6652   \n",
      "4       VIR  Virgin Islands (U.S.)         50.0700   \n",
      "5       VNM               Viet Nam         41.0000   \n",
      "..      ...                    ...             ...   \n",
      "211     AGO                 Angola         21.3623   \n",
      "212     AND                Andorra         86.1000   \n",
      "214     DZA                Algeria         29.5000   \n",
      "215     ALB                Albania         54.3000   \n",
      "216     AFG            Afghanistan          7.0000   \n",
      "\n",
      "     Gross Domestic Product (GDP) per capita, PPP  Population, Total  \n",
      "0                                     3588.862715         13855753.0  \n",
      "1                                     3621.466084         15737793.0  \n",
      "3                                     5990.426615          4173398.0  \n",
      "4                                    42698.552089           107882.0  \n",
      "5                                     8794.481175         91235504.0  \n",
      "..                                            ...                ...  \n",
      "211                                  10262.847015         27128337.0  \n",
      "212                                  61700.237094            71621.0  \n",
      "214                                  15249.570446         38760168.0  \n",
      "215                                  12909.240795          2889104.0  \n",
      "216                                   3024.982120         32716210.0  \n",
      "\n",
      "[190 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import wbgapi as wb\n",
    "\n",
    "# List of indicators\n",
    "indicators = ['NY.GDP.PCAP.PP.KD', 'IT.NET.USER.ZS', 'SP.POP.TOTL']\n",
    "\n",
    "try:\n",
    "    # Fetch data for all countries in 2014\n",
    "    data = wb.data.DataFrame(indicators, time=2014,\n",
    "                             skipAggs=True, columns='series', labels=True)\n",
    "\n",
    "    # Reset index for easier readability\n",
    "    data.reset_index(inplace=True)\n",
    "\n",
    "    # Drop rows with any NaN values\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    data.rename(columns={\n",
    "        'SP.POP.TOTL': 'Population, Total',\n",
    "        'IT.NET.USER.ZS': 'Internet users',\n",
    "        'NY.GDP.PCAP.PP.KD': 'Gross Domestic Product (GDP) per capita, PPP'\n",
    "    }, inplace=True)\n",
    "\n",
    "    print(data)\n",
    "except wb.APIError as e:\n",
    "    print(f\"API error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next only keep rows where there are at least 5 Million internet users. Keep in Mind that the Internet Users are per 100 people, so don't forget to take the population into account.\n",
    "\n",
    "For example in the dataset Austria has 80.995825 internet users per 100 people, while 8546356 people living in Austria. This means Austria has 6922191.55 internet users in total. The calculation for that is as follows:\n",
    "$\n",
    "\\begin{align}\n",
    "internet\\_users = population \\cdot \\frac{internet\\_user\\_per\\_100}{100}\n",
    "\\end{align}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    economy               Country  Internet users per 100  \\\n",
      "5       VNM              Viet Nam                 41.0000   \n",
      "8       UZB            Uzbekistan                 35.5000   \n",
      "10      USA         United States                 73.0000   \n",
      "11      GBR        United Kingdom                 91.6133   \n",
      "12      ARE  United Arab Emirates                 90.4000   \n",
      "..      ...                   ...                     ...   \n",
      "205     AUT               Austria                 80.9958   \n",
      "206     AUS             Australia                 84.0000   \n",
      "209     ARG             Argentina                 64.7000   \n",
      "211     AGO                Angola                 21.3623   \n",
      "214     DZA               Algeria                 29.5000   \n",
      "\n",
      "     Gross Domestic Product (GDP) per capita, PPP  Population, Total  \\\n",
      "5                                     8794.481175         91235504.0   \n",
      "8                                     6356.887253         30757700.0   \n",
      "10                                   63214.895346        318386329.0   \n",
      "11                                   51054.592986         64602298.0   \n",
      "12                                   63309.310961          8835951.0   \n",
      "..                                            ...                ...   \n",
      "205                                  62378.971893          8546356.0   \n",
      "206                                  54610.393806         23475686.0   \n",
      "209                                  28442.248189         42669500.0   \n",
      "211                                  10262.847015         27128337.0   \n",
      "214                                  15249.570446         38760168.0   \n",
      "\n",
      "     Internet users, Total  \n",
      "5             3.740656e+07  \n",
      "8             1.091898e+07  \n",
      "10            2.324220e+08  \n",
      "11            5.918430e+07  \n",
      "12            7.987700e+06  \n",
      "..                     ...  \n",
      "205           6.922189e+06  \n",
      "206           1.971958e+07  \n",
      "209           2.760717e+07  \n",
      "211           5.795237e+06  \n",
      "214           1.143425e+07  \n",
      "\n",
      "[62 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import wbgapi as wb\n",
    "import pandas as pd\n",
    "\n",
    "# List of indicators\n",
    "indicators = ['NY.GDP.PCAP.PP.KD', 'IT.NET.USER.ZS', 'SP.POP.TOTL']\n",
    "\n",
    "try:\n",
    "    # Fetch data for all countries in 2014\n",
    "    data = wb.data.DataFrame(indicators, time=2014,\n",
    "                             skipAggs=True, columns='series', labels=True)\n",
    "\n",
    "    # Reset index for easier readability\n",
    "    data.reset_index(inplace=True)\n",
    "\n",
    "    # Drop rows with any NaN values\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    data.rename(columns={\n",
    "        'SP.POP.TOTL': 'Population, Total',\n",
    "        'IT.NET.USER.ZS': 'Internet users per 100',\n",
    "        'NY.GDP.PCAP.PP.KD': 'Gross Domestic Product (GDP) per capita, PPP'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Calculate the total internet users\n",
    "    data['Internet users, Total'] = data['Population, Total'] * (data['Internet users per 100'] / 100)\n",
    "\n",
    "    # Filter to keep only rows where the total internet users are at least 5 million\n",
    "    data = data[data['Internet users, Total'] >= 5_000_000]\n",
    "\n",
    "    print(data)\n",
    "except wb.APIError as e:\n",
    "    print(f\"API error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 The Future Orientation Index in Google Trends\n",
    "## 2.1 Download data from Google Trends\n",
    "\n",
    "You can download the data from Google Trends following these steps:\n",
    "\n",
    "1) Log out from your google account or set its language to English\n",
    "\n",
    "2) Go to trends.google.com and search for 2013 \n",
    "\n",
    "3) Add 2015 as a search term\n",
    "\n",
    "4) Select custom time rage: full year: 2014\n",
    "\n",
    "5) Set the region to “Worldwide”. You can also try with this link (it links to the google trends page with all settings from above applied): https://trends.google.com/trends/explore?date=2014-01-01%202014-12-31&q=2013,2015\n",
    "\n",
    "6) Go to the map at “Compared breakdown by region” and tick on “include low search volume regions”\n",
    "\n",
    "7) On the top right menu click the download button to get a geoMap.csv file\n",
    "\n",
    "If you have problems getting the file from the web interface, we also included it in the github repository.\n",
    "\n",
    "Load the .csv file in a pandas data frame. Notice in the file the first 3 Lines are actually only information (while the third is the header). You can skip these lines by using `skiprows=3` in `pd.read_csv`. Set the headers to `\"Country\", \"G2013\", \"G2015\"`, this can be done by the keyword argument `names` in `pd.read_csv`.\n",
    "\n",
    "Now remove again all rows containing `NaN`.\n",
    "\n",
    "All the percentage data is saved as a string containing the `%` symbol. You can remove this with `pandas` [`str.replace`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html) method and save them as integer with `pandas` [`astype`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html) method. Do this for column `G2013` and `G2015`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Country  G2013  G2015\n",
      "0           Algerien     65     35\n",
      "1    Republik Moldau     87     13\n",
      "2           Armenien     85     15\n",
      "3           Pakistan     85     15\n",
      "5         Kasachstan     81     19\n",
      "..               ...    ...    ...\n",
      "229           Malawi     62     38\n",
      "230         Südkorea     70     30\n",
      "231           Taiwan     61     39\n",
      "232         Südsudan     67     33\n",
      "233            Japan     54     46\n",
      "\n",
      "[231 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file, skip the first 3 rows, and set custom headers\n",
    "data = pd.read_csv('geoMap.csv', skiprows=3, names=[\n",
    "                   \"Country\", \"G2013\", \"G2015\"])\n",
    "\n",
    "# Remove rows with any NaN values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Remove '%' symbol and convert the data to integers for 'G2013' and 'G2015'\n",
    "data['G2013'] = data['G2013'].str.replace('%', '').astype(int)\n",
    "data['G2015'] = data['G2015'].str.replace('%', '').astype(int)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Calculate the Future Orientation Index\n",
    "\n",
    "In the following code chunk, make a new column in the Google Trends dataframe with the Future Orientation Index, which is the ratio between the search volume for 2015 and 2013 in 2014 for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Country  G2013  G2015  Future Orientation Index\n",
      "0           Algerien     65     35                  0.538462\n",
      "1    Republik Moldau     87     13                  0.149425\n",
      "2           Armenien     85     15                  0.176471\n",
      "3           Pakistan     85     15                  0.176471\n",
      "5         Kasachstan     81     19                  0.234568\n",
      "..               ...    ...    ...                       ...\n",
      "229           Malawi     62     38                  0.612903\n",
      "230         Südkorea     70     30                  0.428571\n",
      "231           Taiwan     61     39                  0.639344\n",
      "232         Südsudan     67     33                  0.492537\n",
      "233            Japan     54     46                  0.851852\n",
      "\n",
      "[231 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file, skip the first 3 rows, and set custom headers\n",
    "data = pd.read_csv('geoMap.csv', skiprows=3, names=[\n",
    "                   \"Country\", \"G2013\", \"G2015\"])\n",
    "\n",
    "# Remove rows with any NaN values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Remove '%' symbol and convert the data to integers for 'G2013' and 'G2015'\n",
    "data['G2013'] = data['G2013'].str.replace('%', '').astype(int)\n",
    "data['G2015'] = data['G2015'].str.replace('%', '').astype(int)\n",
    "\n",
    "# Calculate the Future Orientation Index and add as a new column\n",
    "data['Future Orientation Index'] = data['G2015'] / data['G2013']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Merge with World Bank data\n",
    "\n",
    "Merge the WDI and google trends data frames, using the name of the country. For this you can use `pandas` [`merge`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   economy   Country  Internet users per 100  \\\n",
      "0      UKR   Ukraine                 46.2360   \n",
      "1      THA  Thailand                 34.8861   \n",
      "2      PRT  Portugal                 64.5924   \n",
      "3      PER      Peru                 40.2447   \n",
      "4      PAK  Pakistan                 10.0000   \n",
      "5      NGA   Nigeria                 21.0000   \n",
      "6      MYS  Malaysia                 63.6654   \n",
      "7      JPN     Japan                 89.1068   \n",
      "8      ISR    Israel                 75.0178   \n",
      "9      GHA     Ghana                 19.0000   \n",
      "10     ECU   Ecuador                 45.5904   \n",
      "11     CHN     China                 47.9000   \n",
      "12     CHL     Chile                 61.1100   \n",
      "13     BLR   Belarus                 59.0163   \n",
      "14     AGO    Angola                 21.3623   \n",
      "\n",
      "    Gross Domestic Product (GDP) per capita, PPP  Population, Total  \\\n",
      "0                                   17255.289062       4.527216e+07   \n",
      "1                                   18390.862640       6.996094e+07   \n",
      "2                                   35102.799237       1.040106e+07   \n",
      "3                                   14135.333314       3.035395e+07   \n",
      "4                                    4650.751053       2.082516e+08   \n",
      "5                                    6197.487502       1.793790e+08   \n",
      "6                                   26905.047816       3.060646e+07   \n",
      "7                                   42909.005661       1.272760e+08   \n",
      "8                                   40766.846889       8.215700e+06   \n",
      "9                                    5588.230006       2.819636e+07   \n",
      "10                                  14115.387319       1.595799e+07   \n",
      "11                                  13696.517495       1.371860e+09   \n",
      "12                                  27790.247526       1.768711e+07   \n",
      "13                                  26564.431126       9.448515e+06   \n",
      "14                                  10262.847015       2.712834e+07   \n",
      "\n",
      "    Internet users, Total  G2013  G2015  Future Orientation Index  \n",
      "0            2.093203e+07     79     21                  0.265823  \n",
      "1            2.440664e+07     74     26                  0.351351  \n",
      "2            6.718296e+06     66     34                  0.515152  \n",
      "3            1.221586e+07     74     26                  0.351351  \n",
      "4            2.082516e+07     85     15                  0.176471  \n",
      "5            3.766959e+07     61     39                  0.639344  \n",
      "6            1.948572e+07     57     43                  0.754386  \n",
      "7            1.134116e+08     54     46                  0.851852  \n",
      "8            6.163237e+06     69     31                  0.449275  \n",
      "9            5.357308e+06     71     29                  0.408451  \n",
      "10           7.275313e+06     76     24                  0.315789  \n",
      "11           6.571209e+08     92      8                  0.086957  \n",
      "12           1.080859e+07     60     40                  0.666667  \n",
      "13           5.576164e+06     77     23                  0.298701  \n",
      "14           5.795237e+06     69     31                  0.449275  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and preprocess the Google Trends data\n",
    "google_trends = pd.read_csv('geoMap.csv', skiprows=3, names=[\n",
    "                        \"Country\", \"G2013\", \"G2015\"])\n",
    "google_trends.dropna(inplace=True)\n",
    "google_trends['G2013'] = google_trends['G2013'].str.replace(\n",
    "'%', '').astype(int)\n",
    "google_trends['G2015'] = google_trends['G2015'].str.replace(\n",
    "'%', '').astype(int)\n",
    "google_trends['Future Orientation Index'] = google_trends['G2015'] / \\\n",
    "google_trends['G2013']\n",
    "\n",
    "merged_data = pd.merge(data, google_trends, on=\"Country\", how=\"inner\")\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Testing the correlation between GDP and FOI\n",
    "# 3.1 Visualize FOI vs GDP\n",
    "\n",
    "Now that you have the FOI index, GPD per capita and PPP value for each country, you can make a scatter plot of FOI vs GDP.\n",
    "\n",
    "For this you can use the [`scatter`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html) method of `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Measure Pearson’s correlation\n",
    "\n",
    "In the following chunk, calculate Pearson’s correlation coefficient between GDP and FOI.\n",
    "\n",
    "For this you can use the [`pearsonr`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html) method of `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Measure correlation after shuffling\n",
    "\n",
    "What happens if we permute the data (e.g. shuffle the FOIs) and repeat the above analysis? Do you find any difference between the two plots and two Pearson’s correlation coefficients?\n",
    "\n",
    "For the shuffeling you can use `pandas` [`sample`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) method with `frac` set to 1.\n",
    "\n",
    "This test shows you if the correlation is happend by random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the calculation with 1000 permutations and plot the histogram of the resulting values. Add a line with the value of the correlation without permutation. Is it far or close to the permuted values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To learn more\n",
    "### Check robustness\n",
    "* What result do you get if you use other years? What if you choose one of the earliest years in Google trends?\n",
    "* How do results change if you use a different threshod instead of 5 Million Internet users?\n",
    "    \n",
    "### Test other hypotheses\n",
    "* Is future orientation generating wealth? Or is wealth enabling to look more to the future?\n",
    "* Is the FOI really measuring orientation to the future? Could it be something else?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Using Google Trends data to model Flu Trends\n",
    "\n",
    "## Tasks\n",
    "\n",
    "Use the [pytrends module](https://pypi.org/project/pytrends/) to get weekly Google Trends data concerning the Flu/Influenza virus from the beginning of 2014 until the end of 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hint:*** *the pytrends module currently has a bug. If you get a `TooManyRequestsError` despite following the documentation, try following the advice outlined [here](https://github.com/GeneralMills/pytrends/issues/573#issuecomment-1501897119) or [here](https://github.com/GeneralMills/pytrends/issues/561#issuecomment-1462899426) (both solve the issue).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install requirements. \n",
    "\n",
    "The following cell contains all the necessary dependencies needed for this task. If you run the cell everything will be installed.  \n",
    "* [`pytrends`]((https://pypi.org/project/pytrends/)\n",
    "* [`requests`]\n",
    "* [`statsmodels`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U pytrends\n",
    "! pip install requests\n",
    "! pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Google Trends data\n",
    "\n",
    "## 1.1 Get weekly Google Trends data concerning the Flu/Influenza virus\n",
    "\n",
    "- Create an instance of the `TrendReq` class\n",
    "- Find the appropriate query term (i.e., influenza). The TrendReq class includes a method `suggestions`, which should help you in this task (the query term can look like e.g. `/m/03x_m3v`).\n",
    "- Specify the correct geographical region, the timeframe (i.e. from the beginning of 2014 until the end of 2018), and the key-word list. Use the `build_payload` method to store this information for future requests.\n",
    "- Use the `interest_over_time` method to get the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 US National data\n",
    "\n",
    "## Get data regarding the occurance of Influenza like Illnesses in the US\n",
    "\n",
    "In the `Excercise 1` folder you will find a file named `ILINet.csv`, which contains data regarding the occurance of Influenza like Illnesses in the US. You can also find the data and the corresponding [documentation](https://gis.cdc.gov/grasp/fluview/FluViewPhase2QuickReferenceGuide.pdf) on the CDC's [FluView interactive dashboard](https://gis.cdc.gov/grasp/fluview/fluportaldashboard.html).\n",
    "<br>\n",
    "- Read the csv file, and store it as a [pandas](https://pypi.org/project/pandas/) dataframe. You might need to use the `skiprows` argument of the `read_csv` method to be able to load the data correctly.\n",
    "- Select the columns named `YEAR`, `WEEK`, and `% WEIGHTED ILI` which will be needed for our analysis. Additionally, drop the rows which store observations from before 2014, or later than 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Testing the correlation between flu interest and US National data\n",
    "\n",
    "# 3.1 Visualize flu interest vs US National data\n",
    "\n",
    "Now that you have the US National data regarding the occurance of Influenza like Illnesses in the US, you can make a scatter plot of `flu interest` vs `% WEIGHTED ILI`.\n",
    "\n",
    "For this you can use the [`scatter`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html) method of `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Measure Pearson’s correlation\n",
    "\n",
    "In the following chunk, calculate Pearson’s correlation coefficient between `flu interest` and `% WEIGHTED ILI`.\n",
    "\n",
    "For this you can use the [`pearsonr`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html) method of `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Measure correlation after shuffling\n",
    "\n",
    "What happens if we permute the data (e.g. shuffle the `flu interest`s) and repeat the above analysis? Do you find any difference between the two plots and two Pearson’s correlation coefficients?\n",
    "\n",
    "For the shuffeling you can use `pandas` [`sample`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) method with `frac` set to 1.\n",
    "\n",
    "This test shows you if the correlation is happend by random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the calculation with 1000 permutations and plot the histogram of the resulting values. Add a line with the value of the correlation without permutation. Is it far or close to the permuted values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To learn more\n",
    "\n",
    "#### Prediction\n",
    "* Download the Google Trends data for 2019, and use your models to predict the values of `% WEIGHTED ILI`.\n",
    "* Do the models make good predictions? Which model performs better?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
