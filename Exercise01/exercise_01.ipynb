{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Correlation of Future Orientation Index and Gross Domestic Product\n",
    "## Tasks\n",
    "\n",
    "In this exercise, we try to reproduce the findings of the article “Quantifying the Advantage of Looking Forward” http://www.nature.com/articles/srep00350.\n",
    "\n",
    "According to the study, the GDP per capita of countries is positively correlated to how much their population searches in Google for the next year, relative to how much they search for the previous year.\n",
    "\n",
    "This ratio is called the Future Orientation Index (FOI). So for example for the year 2017 the FOI can be calculated as: FOI = number of searches for the term “2018” / number of searches for the term “2016”.\n",
    "\n",
    "You will do the following tasks:\n",
    "1. Aquire World Bank Data\n",
    "2. Calculate the Future Orientation Index in Google Trends\n",
    "3. Test the correlation between GDP and FOI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install requirements. \n",
    "\n",
    "The following cell contains all the necessary dependencies needed for this task. If you run the cell everything will be installed.  \n",
    "* [`wbgapi`](https://github.com/tgherzog/wbgapi) is a Python package which provides modern, pythonic access to the World Bank's data API. [Here](https://github.com/tgherzog/wbgapi) is the documentation of `wbgapi`.\n",
    "* [`pandas`](https://pandas.pydata.org/docs/index.html) is a Python package for creating and working with tabular data. [Here](https://pandas.pydata.org/docs/reference/index.html) is the documentation of `pandas`.\n",
    "* [`matplotlib`](https://matplotlib.org/) is a Python package for creating plots. [Here](https://matplotlib.org/stable/api/index.html) is the documentation of `matplotlib`.\n",
    "* [`scipy`](https://scipy.org/) is a Python package with different algorithms for scientific computing. [Here](https://docs.scipy.org/doc/scipy/reference/index.html#scipy-api) is the documentation of `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install wbgapi\n",
    "! pip install pandas\n",
    "! pip install matplotlib\n",
    "! pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import requirements\n",
    "The cell below imports all necessary dependancies. Make sure they are installed (see cell above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wbgapi as wb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 World Bank Data\n",
    "## 1.1 Download WDI data\n",
    "\n",
    "From the WDI we need three indicators:\n",
    "* Gross Domestic Product (GDP) per capita corrected by the Purchase Power Parity (PPP in current or 2005 international $, `\"NY.GDP.PCAP.PP.KD\"`)\n",
    "* The amount of Internet users (per 100 people, `\"IT.NET.USER.ZS\"`\n",
    "* The total population (described as as \"Population, Total\", `\"SP.POP.TOTL\"`)\n",
    "\n",
    "In the following code chunk, download all data (including extras) for all countries in year 2014 and save it as a pandas data frame. See [here](https://github.com/tgherzog/wbgapi#accessing-data) how to use the `data` subpackage of `wbgapi`.\n",
    "\n",
    "Hint: To remove aggregates (economic regions defined by the World Bank) and include only countries, use `skipAggs=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    economy  IT.NET.USER.ZS  NY.GDP.PCAP.PP.KD  SP.POP.TOTL\n",
      "0       ABW         83.7800       37433.084090     103594.0\n",
      "1       AFG          7.0000        3024.982120   32716210.0\n",
      "2       AGO         21.3623       10262.847015   27128337.0\n",
      "3       ALB         54.3000       12909.240795    2889104.0\n",
      "4       AND         86.1000       61700.237094      71621.0\n",
      "..      ...             ...                ...          ...\n",
      "212     XKX             NaN        9150.835788    1812771.0\n",
      "213     YEM         22.5500                NaN   27753304.0\n",
      "214     ZAF         49.0000       14869.047901   54729551.0\n",
      "215     ZMB          6.5000        3621.466084   15737793.0\n",
      "216     ZWE         16.3647        3588.862715   13855753.0\n",
      "\n",
      "[217 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import wbgapi as wb\n",
    "\n",
    "# List of indicators\n",
    "indicators = ['NY.GDP.PCAP.PP.KD', 'IT.NET.USER.ZS', 'SP.POP.TOTL']\n",
    "\n",
    "try:\n",
    "    # Fetch data for all countries in 2014\n",
    "    data = wb.data.DataFrame(indicators, time=2014,\n",
    "                             skipAggs=True, columns='series')\n",
    "\n",
    "    # Reset index for easier readability\n",
    "    data.reset_index(inplace=True)\n",
    "\n",
    "    print(data)\n",
    "except wb.APIError as e:\n",
    "    print(f\"API error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now drop any row that has `NaN` for this you can use `pandas` [`dropna`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    economy  Internet users  Gross Domestic Product (GDP) per capita, PPP  \\\n",
      "0       ABW         83.7800                                  37433.084090   \n",
      "1       AFG          7.0000                                   3024.982120   \n",
      "2       AGO         21.3623                                  10262.847015   \n",
      "3       ALB         54.3000                                  12909.240795   \n",
      "4       AND         86.1000                                  61700.237094   \n",
      "..      ...             ...                                           ...   \n",
      "210     VUT         18.8000                                   3202.417111   \n",
      "211     WSM         21.2000                                   6196.958924   \n",
      "214     ZAF         49.0000                                  14869.047901   \n",
      "215     ZMB          6.5000                                   3621.466084   \n",
      "216     ZWE         16.3647                                   3588.862715   \n",
      "\n",
      "     Population, Total  \n",
      "0             103594.0  \n",
      "1           32716210.0  \n",
      "2           27128337.0  \n",
      "3            2889104.0  \n",
      "4              71621.0  \n",
      "..                 ...  \n",
      "210           269927.0  \n",
      "211           201757.0  \n",
      "214         54729551.0  \n",
      "215         15737793.0  \n",
      "216         13855753.0  \n",
      "\n",
      "[190 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import wbgapi as wb\n",
    "\n",
    "# List of indicators\n",
    "indicators = ['NY.GDP.PCAP.PP.KD', 'IT.NET.USER.ZS', 'SP.POP.TOTL']\n",
    "\n",
    "try:\n",
    "    # Fetch data for all countries in 2014\n",
    "    data = wb.data.DataFrame(indicators, time=2014,\n",
    "                             skipAggs=True, columns='series')\n",
    "\n",
    "    # Reset index for easier readability\n",
    "    data.reset_index(inplace=True)\n",
    "\n",
    "    # Drop rows with any NaN values\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    data.rename(columns={\n",
    "        'SP.POP.TOTL': 'Population, Total',\n",
    "        'IT.NET.USER.ZS': 'Internet users',\n",
    "        'NY.GDP.PCAP.PP.KD': 'Gross Domestic Product (GDP) per capita, PPP'\n",
    "    }, inplace=True)\n",
    "\n",
    "    print(data)\n",
    "except wb.APIError as e:\n",
    "    print(f\"API error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next only keep rows where there are at least 5 Million internet users. Keep in Mind that the Internet Users are per 100 people, so don't forget to take the population into account.\n",
    "\n",
    "For example in the dataset Austria has 80.995825 internet users per 100 people, while 8546356 people living in Austria. This means Austria has 6922191.55 internet users in total. The calculation for that is as follows:\n",
    "$\n",
    "\\begin{align}\n",
    "internet\\_users = population \\cdot \\frac{internet\\_user\\_per\\_100}{100}\n",
    "\\end{align}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    economy  Internet users per 100  \\\n",
      "2       AGO                 21.3623   \n",
      "5       ARE                 90.4000   \n",
      "6       ARG                 64.7000   \n",
      "10      AUS                 84.0000   \n",
      "11      AUT                 80.9958   \n",
      "..      ...                     ...   \n",
      "201     UKR                 46.2360   \n",
      "203     USA                 73.0000   \n",
      "204     UZB                 35.5000   \n",
      "209     VNM                 41.0000   \n",
      "214     ZAF                 49.0000   \n",
      "\n",
      "     Gross Domestic Product (GDP) per capita, PPP  Population, Total  \\\n",
      "2                                    10262.847015         27128337.0   \n",
      "5                                    63309.310961          8835951.0   \n",
      "6                                    28442.248189         42669500.0   \n",
      "10                                   54610.393806         23475686.0   \n",
      "11                                   62378.971893          8546356.0   \n",
      "..                                            ...                ...   \n",
      "201                                  17255.289062         45272155.0   \n",
      "203                                  63214.895346        318386329.0   \n",
      "204                                   6356.887253         30757700.0   \n",
      "209                                   8794.481175         91235504.0   \n",
      "214                                  14869.047901         54729551.0   \n",
      "\n",
      "     Internet users, Total  \n",
      "2             5.795237e+06  \n",
      "5             7.987700e+06  \n",
      "6             2.760717e+07  \n",
      "10            1.971958e+07  \n",
      "11            6.922189e+06  \n",
      "..                     ...  \n",
      "201           2.093203e+07  \n",
      "203           2.324220e+08  \n",
      "204           1.091898e+07  \n",
      "209           3.740656e+07  \n",
      "214           2.681748e+07  \n",
      "\n",
      "[62 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import wbgapi as wb\n",
    "import pandas as pd\n",
    "\n",
    "# List of indicators\n",
    "indicators = ['NY.GDP.PCAP.PP.KD', 'IT.NET.USER.ZS', 'SP.POP.TOTL']\n",
    "\n",
    "try:\n",
    "    # Fetch data for all countries in 2014\n",
    "    data = wb.data.DataFrame(indicators, time=2014,\n",
    "                             skipAggs=True, columns='series')\n",
    "\n",
    "    # Reset index for easier readability\n",
    "    data.reset_index(inplace=True)\n",
    "\n",
    "    # Drop rows with any NaN values\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    data.rename(columns={\n",
    "        'SP.POP.TOTL': 'Population, Total',\n",
    "        'IT.NET.USER.ZS': 'Internet users per 100',\n",
    "        'NY.GDP.PCAP.PP.KD': 'Gross Domestic Product (GDP) per capita, PPP'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Calculate the total internet users\n",
    "    data['Internet users, Total'] = data['Population, Total'] * (data['Internet users per 100'] / 100)\n",
    "\n",
    "    # Filter to keep only rows where the total internet users are at least 5 million\n",
    "    data = data[data['Internet users, Total'] >= 5_000_000]\n",
    "\n",
    "    print(data)\n",
    "except wb.APIError as e:\n",
    "    print(f\"API error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 The Future Orientation Index in Google Trends\n",
    "## 2.1 Download data from Google Trends\n",
    "\n",
    "You can download the data from Google Trends following these steps:\n",
    "\n",
    "1) Log out from your google account or set its language to English\n",
    "\n",
    "2) Go to trends.google.com and search for 2013 \n",
    "\n",
    "3) Add 2015 as a search term\n",
    "\n",
    "4) Select custom time rage: full year: 2014\n",
    "\n",
    "5) Set the region to “Worldwide”. You can also try with this link (it links to the google trends page with all settings from above applied): https://trends.google.com/trends/explore?date=2014-01-01%202014-12-31&q=2013,2015\n",
    "\n",
    "6) Go to the map at “Compared breakdown by region” and tick on “include low search volume regions”\n",
    "\n",
    "7) On the top right menu click the download button to get a geoMap.csv file\n",
    "\n",
    "If you have problems getting the file from the web interface, we also included it in the github repository.\n",
    "\n",
    "Load the .csv file in a pandas data frame. Notice in the file the first 3 Lines are actually only information (while the third is the header). You can skip these lines by using `skiprows=3` in `pd.read_csv`. Set the headers to `\"Country\", \"G2013\", \"G2015\"`, this can be done by the keyword argument `names` in `pd.read_csv`.\n",
    "\n",
    "Now remove again all rows containing `NaN`.\n",
    "\n",
    "All the percentage data is saved as a string containing the `%` symbol. You can remove this with `pandas` [`str.replace`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html) method and save them as integer with `pandas` [`astype`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html) method. Do this for column `G2013` and `G2015`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Calculate the Future Orientation Index\n",
    "\n",
    "In the following code chunk, make a new column in the Google Trends dataframe with the Future Orientation Index, which is the ratio between the search volume for 2015 and 2013 in 2014 for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Merge with World Bank data\n",
    "\n",
    "Merge the WDI and google trends data frames, using the name of the country. For this you can use `pandas` [`merge`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Testing the correlation between GDP and FOI\n",
    "# 3.1 Visualize FOI vs GDP\n",
    "\n",
    "Now that you have the FOI index, GPD per capita and PPP value for each country, you can make a scatter plot of FOI vs GDP.\n",
    "\n",
    "For this you can use the [`scatter`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html) method of `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Measure Pearson’s correlation\n",
    "\n",
    "In the following chunk, calculate Pearson’s correlation coefficient between GDP and FOI.\n",
    "\n",
    "For this you can use the [`pearsonr`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html) method of `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Measure correlation after shuffling\n",
    "\n",
    "What happens if we permute the data (e.g. shuffle the FOIs) and repeat the above analysis? Do you find any difference between the two plots and two Pearson’s correlation coefficients?\n",
    "\n",
    "For the shuffeling you can use `pandas` [`sample`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) method with `frac` set to 1.\n",
    "\n",
    "This test shows you if the correlation is happend by random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the calculation with 1000 permutations and plot the histogram of the resulting values. Add a line with the value of the correlation without permutation. Is it far or close to the permuted values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To learn more\n",
    "### Check robustness\n",
    "* What result do you get if you use other years? What if you choose one of the earliest years in Google trends?\n",
    "* How do results change if you use a different threshod instead of 5 Million Internet users?\n",
    "    \n",
    "### Test other hypotheses\n",
    "* Is future orientation generating wealth? Or is wealth enabling to look more to the future?\n",
    "* Is the FOI really measuring orientation to the future? Could it be something else?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Using Google Trends data to model Flu Trends\n",
    "\n",
    "## Tasks\n",
    "\n",
    "Use the [pytrends module](https://pypi.org/project/pytrends/) to get weekly Google Trends data concerning the Flu/Influenza virus from the beginning of 2014 until the end of 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hint:*** *the pytrends module currently has a bug. If you get a `TooManyRequestsError` despite following the documentation, try following the advice outlined [here](https://github.com/GeneralMills/pytrends/issues/573#issuecomment-1501897119) or [here](https://github.com/GeneralMills/pytrends/issues/561#issuecomment-1462899426) (both solve the issue).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install requirements. \n",
    "\n",
    "The following cell contains all the necessary dependencies needed for this task. If you run the cell everything will be installed.  \n",
    "* [`pytrends`]((https://pypi.org/project/pytrends/)\n",
    "* [`requests`]\n",
    "* [`statsmodels`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U pytrends\n",
    "! pip install requests\n",
    "! pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Google Trends data\n",
    "\n",
    "## 1.1 Get weekly Google Trends data concerning the Flu/Influenza virus\n",
    "\n",
    "- Create an instance of the `TrendReq` class\n",
    "- Find the appropriate query term (i.e., influenza). The TrendReq class includes a method `suggestions`, which should help you in this task (the query term can look like e.g. `/m/03x_m3v`).\n",
    "- Specify the correct geographical region, the timeframe (i.e. from the beginning of 2014 until the end of 2018), and the key-word list. Use the `build_payload` method to store this information for future requests.\n",
    "- Use the `interest_over_time` method to get the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 US National data\n",
    "\n",
    "## Get data regarding the occurance of Influenza like Illnesses in the US\n",
    "\n",
    "In the `Excercise 1` folder you will find a file named `ILINet.csv`, which contains data regarding the occurance of Influenza like Illnesses in the US. You can also find the data and the corresponding [documentation](https://gis.cdc.gov/grasp/fluview/FluViewPhase2QuickReferenceGuide.pdf) on the CDC's [FluView interactive dashboard](https://gis.cdc.gov/grasp/fluview/fluportaldashboard.html).\n",
    "<br>\n",
    "- Read the csv file, and store it as a [pandas](https://pypi.org/project/pandas/) dataframe. You might need to use the `skiprows` argument of the `read_csv` method to be able to load the data correctly.\n",
    "- Select the columns named `YEAR`, `WEEK`, and `% WEIGHTED ILI` which will be needed for our analysis. Additionally, drop the rows which store observations from before 2014, or later than 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Testing the correlation between flu interest and US National data\n",
    "\n",
    "# 3.1 Visualize flu interest vs US National data\n",
    "\n",
    "Now that you have the US National data regarding the occurance of Influenza like Illnesses in the US, you can make a scatter plot of `flu interest` vs `% WEIGHTED ILI`.\n",
    "\n",
    "For this you can use the [`scatter`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html) method of `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Measure Pearson’s correlation\n",
    "\n",
    "In the following chunk, calculate Pearson’s correlation coefficient between `flu interest` and `% WEIGHTED ILI`.\n",
    "\n",
    "For this you can use the [`pearsonr`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html) method of `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Measure correlation after shuffling\n",
    "\n",
    "What happens if we permute the data (e.g. shuffle the `flu interest`s) and repeat the above analysis? Do you find any difference between the two plots and two Pearson’s correlation coefficients?\n",
    "\n",
    "For the shuffeling you can use `pandas` [`sample`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) method with `frac` set to 1.\n",
    "\n",
    "This test shows you if the correlation is happend by random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the calculation with 1000 permutations and plot the histogram of the resulting values. Add a line with the value of the correlation without permutation. Is it far or close to the permuted values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To learn more\n",
    "\n",
    "#### Prediction\n",
    "* Download the Google Trends data for 2019, and use your models to predict the values of `% WEIGHTED ILI`.\n",
    "* Do the models make good predictions? Which model performs better?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
